#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import json
import re
import time
import datetime
import subprocess
import itertools
import functools

from signal import signal, SIGPIPE, SIG_DFL
signal(SIGPIPE,SIG_DFL)

def concat( ll ):
    return list(itertools.chain(*ll))

def nowstr(fmt="%Y-%m-%dT%H:%M:%S"):
        return datetime.datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

##  logging
def change_state(obj, method_arglist_tpls):
    for m_as in method_arglist_tpls:
        getattr(obj, m_as[0])(*m_as[1])
    return obj

from logging import getLogger, StreamHandler, Formatter
def loginit(logname, format="%(message)s", stream=sys.stderr, level=15, datefmt="%Y/%m/%dT%H:%M:%S" ):
    return change_state(getLogger(logname), [
        ("setLevel", [level]),
        ("addHandler", [change_state(
            StreamHandler(stream),[("setFormatter", [Formatter(fmt=format,datefmt=datefmt)])]
        )])
      ])

def traclog( f ):
    @functools.wraps(f)
    def _f(*args, **kwargs):
        logger.debug("ENTER:{0} {1}".format( f.__name__, kwargs if kwargs else args))
        result = f(*args, **kwargs)
        logger.debug("RETRN:{0} {1}".format( f.__name__, result))
        return result
    return _f

loggercfg = {
  "level": 20,
}
logstdcfg = {
  "stream": sys.stdout,
  "level": 15,
}

logger = loginit(__name__,**loggercfg)
logstd = loginit("std",**logstdcfg)

reg_strs=[
    #    Linux 2.6.32-431.17.1.el6.x86_64 (jpn-zaq50) \t06/23/2015 \t_x86_64_\t(4 CPU)
    #    Linux 2.6.32-431.17.1.el6.x86_64 (jpn-zaq50)    04/17/15        _x86_64_        (4 CPU)
    #15:27:24        CPU      %usr     %nice      %sys   %iowait    %steal      %irq     %soft    %guest     %idle
    #15:27:26        all     36.56      0.00     24.25      0.00      0.00      0.00      0.00      1.13     38.07
    "^(?P<time>\d{2}:\d{2}:\d{2}) (?P<noon>AM|PM){0,1}\s+(?P<cols>(\S*[^\s0-9\.\-\+]\S*\s+){0,}\S*[^\s0-9\.\-\+]\S*)\s*$",
    "^(?P<time>\d{2}:\d{2}:\d{2}) (?P<noon>AM|PM){0,1}\s+(?P<vals>(\S+\s+){0,}[0-9\.\-\+]+)\s*$",
    "^(?P<junk>Average:.*)\s*$",
    "^\s*(?P<uname>Linux\s+\S+)\s+(?P<host>\S+)\s+(?P<date>\S+)\s+\S+\s+\((?P<numcpu>\d+)\s+CPU\)\s*$",
]

def sar_datetime(start_date):
    """
    >>> import sar_datetime
    >>> gen=sar_datetime.sar_datetime("06/02/2015")
    >>> next(gen)
    '2015-06-02 00:00:00'
    >>> gen.send("12:00:00")
    '2015-06-02 12:00:00'
    >>> gen.send("13:00:00")
    '2015-06-02 13:00:00'
    >>> gen.send("00:00:00")
    '2015-06-03 00:00:00'
    """
    current_date=None
    for fmt in ["%m/%d/%y", "%m/%d/%Y"]:
        try:
            current_date=datetime.datetime.strptime(start_date, fmt)
            break
        except ValueError as e:
            pass

    current_time=datetime.datetime.strptime("00:00:00", "%H:%M:%S")
    while True:
        timestr = ( yield "{0}T{1}".format(current_date.strftime("%Y-%m-%d"),current_time.strftime("%H:%M:%S")) )
        if not timestr:
            continue
        if not timestr[1]:
            raw_time = datetime.datetime.strptime(timestr[0], "%H:%M:%S")
        else:
            raw_time = datetime.datetime.strptime("{0} {1}".format(*timestr), "%I:%M:%S %p") 
        if raw_time < current_time:
            current_date+=datetime.timedelta(days=1)
        current_time = raw_time


def loop_sar(iter,regs,excludes):
    exset=set(excludes)
    timeit=sar_datetime(time.strftime("%m/%d/%Y"))
    timeit.next()
    d={}
    for l in iter:
        logger.debug(l)
        for reg in regs:
            match=reg.search(l) 
            if not match or "junk" in match.groupdict(): continue
            if "cols" in match.groupdict(): d={}
            d.update(match.groupdict())
            if 'vals' in d:
                cols=d['cols'].split()
                if set(cols) & exset : continue
                yield dict([('time',timeit.send((d['time'],d['noon'])))]+[(k,v) for k,v in zip(cols,d['vals'].split())])
            if 'date' in d:
                timeit=sar_datetime(time.strftime(d['date'])) 
                timeit.next()
            break

@traclog
def loop_pipeline(pipe):
    while True:
        rawline= pipe.stdout.readline().strip()
        #logger.debug("pipe.poll()={0}".format(pipe.poll()))
        if not rawline and pipe.poll()==0: return
        yield rawline


def take_subkey(p, subkeyset):
    for d in p:
        foundkey=list(subkeyset & set(d.keys()))
        if foundkey:
            yield dict([(k,v) if k=="time" else ("{1}.{0}".format(d[foundkey[0]],k),v) for (k,v) in d.items() if not k in list(subkeyset)])
        else:
            yield d
        

def showdict(d):
    return " ".join([d["time"]]+["{0}={1}".format(k,v) for (k,v) in d.items() if not k == "time"])

def timechanged():
    rslt=False
    otime=None
    while True:
        ctime=yield rslt
        rslt=False
        if ctime != otime:
            rslt=[otime,ctime]
        otime=ctime

def init_dat(cfg, dat_first):
    list1=concat(cfg[0].values())
    list2=concat(cfg[1].values())
    target=[]
    subindex={}
    for k in dat_first.keys():
        for (gk,gl) in cfg[0].items():
            if k in gl:
                target.append(k)
                subindex[k]=gk
                break
        if k in target: continue
        for (gk,gl) in cfg[1].items():
            for ptn in gl:
                if k.endswith(ptn):
                    target.append(k)
                    subindex[k]=gk
                    break
    return dict([(k,dat_first[k]) for k in target]),subindex

def loop_filtered(iter,list_exact,list_ptn):
    for d in iter:
        logger.debug("list_exact:{0}".format(list_exact))
        _l=[(k,v) for (k,v) in d.items() if k in list_exact or k.split(".")[0] in list_ptn]
        if not _l: continue
        yield d["time"], _l

def filtered_out(i_d,i_t,cfg):
    list1=concat(cfg[0].values())
    list2=concat(cfg[1].values())
    i_filtered=loop_filtered(i_d,list1,list2)
    dat={}
    otime=None
    ctime=None
    t_changed=False
    subindex=None
    labels=[]
    while True:
        for (t,l) in i_filtered:
            t_changed = i_t.send(t)
            if t_changed:
                (otime,ctime)=t_changed
                dat[ctime]={}
            for (k,v) in [x for x in l]:
                dat[ctime][k]=v
            if t_changed: break
        if not otime:
            continue
        elif not labels:
            labels=sorted(dat[otime].keys())
            logger.info(" ".join(["time"]+labels))
        logger.info(" ".join([otime] + [dat[otime][k] for k in labels]))
        del(dat[otime])
    return

@traclog
def loop_cfg(i_d,i_t,cfg,testdir,hostname,log_to_file):
    list1=concat(cfg[0].values())
    list2=concat(cfg[1].values())
    i_filtered=loop_filtered(i_d,list1,list2)
    dat={}
    otime=None
    ctime=None
    t_changed=False
    subindex=None
    labels=[]
    output_groups={}
    if log_to_file:
        for path in ["{0}/{1}.{2}".format(testdir,hostname,k) for k in cfg[0].keys()+cfg[1].keys()]:
            if os.path.exists(path):
                logger.error("{0} is already exists".format(path))
                sys.exit(-1)
        output_files=dict([(k,open("{0}/{1}.{2}".format(testdir,hostname,k),"wab")) for k in cfg[0].keys()+cfg[1].keys()])
    while True:
        for (t,l) in i_filtered:
            t_changed = i_t.send(t)
            if t_changed:
                (otime,ctime)=t_changed
                dat[ctime]={}
            for (k,v) in [x for x in l]:
                dat[ctime][k]=v
            if t_changed: break
        if not otime:
            continue
        elif not labels:
            labels=sorted(dat[otime].keys())
            logger.info(" ".join(["time"]+labels))
            for (k,v) in cfg[0].items():
                output_groups[k]=[l for l in labels if l in v]
                if log_to_file:
                    output_files[k].write(" ".join(["time"]+output_groups[k]))
                    output_files[k].write("\n")
                    output_files[k].flush()
                    continue
                logstd.info(" ".join(["time","group"]+output_groups[k]))
            for (k,v) in cfg[1].items():
                output_groups[k]=[l for l in labels if l.split(".")[0] in v]
                if log_to_file:
                    output_files[k].write(" ".join(["time"]+output_groups[k]))
                    output_files[k].write("\n")
                    output_files[k].flush()
                    continue
                logstd.info(" ".join(["time",k]+output_groups[k]))
        logger.info(" ".join([otime] + [dat[otime][k] for k in labels]))
        for (k,v) in output_groups.items():
            if log_to_file:
                output_files[k].write(" ".join([otime]+[dat[otime][dk] for dk in v]))
                output_files[k].write("\n")
                output_files[k].flush()
                continue
            logstd.info(" ".join([otime,k,]+[dat[otime][dk] for dk in v]))
        del(dat[otime])
    return


def simple_out(i_d,i_t):
    dat={}
    otime=None
    ctime=None
    t_changed=False
    while True:
        for l in i_d:
            t_changed = i_t.send(l["time"])
            if t_changed:
                (otime,ctime)=t_changed
                dat[ctime]={}
                for (k,v) in [x for x in l.items() if x[0] !="time"]:
                    dat[ctime][k]=v
                break
            for (k,v) in [x for x in l.items() if x[0] !="time"]:
                dat[ctime][k]=v
        if not otime: continue
        logger.info(json.dumps({otime:dat[otime]}))
        del(dat[otime])
    return

@traclog
def main(opts):
    hostname=os.uname()[1]
    try:
        os.makedirs(opts["directory"])
    except OSError as e:
        if e.errno == 17: pass

    cmd="LANG=C sar {0} -A {1}".format("" if opts["no_sarbin"] else "-o {0}/{1}.sb".format(opts["directory"],hostname), opts["interval"])
    p=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE) 
    i_pipe=loop_sar(loop_pipeline(p),[re.compile(x) for x in reg_strs],opts['excludes'].split(','))
    i_subkey=take_subkey(i_pipe, set(opts["subkeys"].split(",")))
    timechk=timechanged()
    timechk.next()

    if not opts["cfg"]:
        simple_out(i_subkey,timechk)
        return

    loop_cfg(i_subkey,timechk,json.loads(open(opts["cfg"]).read()),opts["directory"],hostname,opts["log_to_file"])


def parsed_opts():
    import optparse
    import os

    opt = optparse.OptionParser()
    opt.add_option("-P", "--prof", default=False, action="store_true", help="get profile [default: %default]" )
    opt.add_option("-L", "--loglevel", default=25, type="int", help="15:info, 10:debug, 5:trace [default: %default]" )
    opt.add_option("-i", "--interval", default=10, type="int", help="interval to sampling [default: %default]" )
    opt.add_option("-n", "--no_sarbin", default=False, action="store_true", help="output to sar binary file[default: %default]" )
    opt.add_option("-E", "--excludes", default="INTR,MHz", help="[default: %default]" )
    opt.add_option("-s", "--subkeys", default="CPU,DEV,IFACE", help="[default: %default]" )
    opt.add_option("-f", "--cfg", default="{0}/psar.json".format(os.path.abspath(os.path.dirname(__file__))), help="[default: %default]" )
    opt.add_option("-d", "--directory", default="{0}/pacdat/{1}".format(os.environ["PWD"] if not "TOOL_ROOT" in os.environ else os.environ["TOOL_ROOT"], datetime.datetime.now().strftime("pac%Y%m%d%H%M%S")), help="[default: %default]" )
    opt.add_option("-l", "--log_to_file", default=False, action="store_true", help="[default: %default]" )

    (opts, args)= opt.parse_args()
    return dict(vars(opts).items() + [("args", args)])

if __name__ == '__main__':
    opts = parsed_opts()
    logger.setLevel(opts['loglevel'])
    if opts['prof']:
      import cProfile
      cProfile.run('main(opts)')
      sys.exit(0)
    main(opts)
